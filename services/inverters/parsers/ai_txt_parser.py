import asyncio
import json
import time
import google.generativeai as genai
from typing import List, Dict
from dotenv import load_dotenv
import os

load_dotenv()


genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    generation_config={
        "temperature": 0.3,
        "top_p": 1,
        "top_k": 40,
        "max_output_tokens": 999999
    }
)


def parse_chunk(index: int, data: str) -> List[Dict]:
    prompt = f"""
Ð”Ñ–Ð¹ ÑÐº Ð¿Ñ€Ð¾Ñ„ÐµÑÑ–Ð¹Ð½Ð¸Ð¹ Ð¿Ð°Ñ€ÑÐµÑ€ Ñ– ÑÐ¿ÐµÑ†Ñ–Ð°Ð»Ñ–ÑÑ‚ Ð· Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ñƒ Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€Ñ–Ð² Ð´Ð»Ñ ÑÐ¾Ð½ÑÑ‡Ð½Ð¸Ñ… ÐµÐ»ÐµÐºÑ‚Ñ€Ð¾ÑÑ‚Ð°Ð½Ñ†Ñ–Ð¹.

ðŸ“Œ Ð“ÐžÐ›ÐžÐ’ÐÐ•: ÑÐ¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ð²Ð¸Ð·Ð½Ð°Ñ‡, Ñ‡Ð¸ Ð´Ñ–Ð¹ÑÐ½Ð¾ Ñ‚Ð¾Ð²Ð°Ñ€ Ñ” Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€Ð¾Ð¼ Ð´Ð»Ñ ÑÐ¾Ð½ÑÑ‡Ð½Ð¸Ñ… ÐµÐ»ÐµÐºÑ‚Ñ€Ð¾ÑÑ‚Ð°Ð½Ñ†Ñ–Ð¹. Ð¯ÐºÑ‰Ð¾ Ñ†Ðµ Ð½Ðµ Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€ â€” ÐŸÐ ÐžÐŸÐ£Ð¡Ð¢Ð˜ Ð¹Ð¾Ð³Ð¾.

Ð— Ñ†ÑŒÐ¾Ð³Ð¾ TXT-Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñƒ Ð¿Ð¾Ð²Ð½Ñ–ÑÑ‚ÑŽ Ð²Ð¸Ñ‚ÑÐ³Ð½Ð¸ Ð´Ð°Ð½Ñ– Ð¿Ñ€Ð¾ Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€Ð¸ Ñ‚Ð° Ð¿ÐµÑ€ÐµÑ‚Ð²Ð¾Ñ€Ð¸ Ñ—Ñ… Ñƒ Ð¼Ð°ÑÐ¸Ð² JSON Ð¾Ð±'Ñ”ÐºÑ‚Ñ–Ð² Ñ‚Ð°ÐºÐ¾Ð³Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ:
{{
  "brand": brand,
  "name": model,
  "full_name": full_name,
  "price": price,
  "inverter_type": inverter_type,
  "generation": generation,
  "string_count": string_count,
  "firmware": firmware,
  "power": power
}}

ðŸ“Œ Ð”ÐµÑ‚Ð°Ð»Ñ– Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ñƒ:
- `brand`: Ð½Ð°Ð·Ð²Ð° Ð±Ñ€ÐµÐ½Ð´Ñƒ Ð¾Ð´Ð½Ð¸Ð¼ ÑÐ»Ð¾Ð²Ð¾Ð¼ (Ð½Ð°Ð²Ñ–Ñ‚ÑŒ ÑÐºÑ‰Ð¾ Ð²ÐºÐ°Ð·Ð°Ð½Ð¾ Ð· Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ¾ÑŽ Ð°Ð±Ð¾ Ñƒ ÑÐºÐ¾Ñ€Ð¾Ñ‡ÐµÐ½Ð½Ñ–)
- `name`: Ð½Ð°Ð·Ð²Ð° Ð¼Ð¾Ð´ÐµÐ»Ñ– Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€Ð° (ÑÐºÑ‰Ð¾ Ð²Ñ–Ð´ÑÑƒÑ‚Ð½Ñ â€” Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð¿Ð¾Ð²ÐµÑ€Ð½Ð¸ Ð±Ñ€ÐµÐ½Ð´)
- `full_name`: Ð¿Ð¾Ð²Ð½Ð° Ð½Ð°Ð·Ð²Ð° Ð°Ð±Ð¾ Ð¾Ð¿Ð¸Ñ Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€Ð°
- `price`: Ð½Ð°Ð¹Ð¼ÐµÐ½ÑˆÐ° Ð¾Ð¿Ñ‚Ð¾Ð²Ð° Ñ†Ñ–Ð½Ð° Ñƒ Ð´Ð¾Ð»Ð°Ñ€Ð°Ñ… Ð¡Ð¨Ð Ð·Ð° 1 ÑˆÑ‚ÑƒÐºÑƒ. Ð¯ÐºÑ‰Ð¾ Ñ†Ñ–Ð½Ð° Ð² Ñ–Ð½ÑˆÑ–Ð¹ Ð²Ð°Ð»ÑŽÑ‚Ñ– â€” Ð¿ÐµÑ€ÐµÐ²ÐµÐ´Ð¸ Ñƒ Ð´Ð¾Ð»Ð°Ñ€Ð¸. Ð¯ÐºÑ‰Ð¾ Ð½ÐµÐ¼Ð°Ñ” Ñ†Ñ–Ð½Ð¸ â€” Ð¿Ð¾Ð²ÐµÑ€Ð½Ð¸ 0.
- `inverter_type`: Ñ‚Ð¸Ð¿ Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€Ð° - "gybrid" (Ð³Ñ–Ð±Ñ€Ð¸Ð´Ð½Ð¸Ð¹), "off-grid" (Ð°Ð²Ñ‚Ð¾Ð½Ð¾Ð¼Ð½Ð¸Ð¹) Ð°Ð±Ð¾ "on-grid" (Ð¼ÐµÑ€ÐµÐ¶ÐµÐ²Ð¸Ð¹). Ð¯ÐºÑ‰Ð¾ Ð½Ðµ Ð²ÐºÐ°Ð·Ð°Ð½Ð¾ â€” Ð¿Ð¾Ð²ÐµÑ€Ð½Ð¸ "gybrid".
- `generation`: Ð¿Ð¾ÐºÐ¾Ð»Ñ–Ð½Ð½Ñ Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€Ð° (Ð½Ð°Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´, "3", "4", "5"). Ð¯ÐºÑ‰Ð¾ Ð½Ðµ Ð²ÐºÐ°Ð·Ð°Ð½Ð¾ â€” Ð¿Ð¾Ð²ÐµÑ€Ð½Ð¸ "4".
- `string_count`: ÐºÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ ÑÑ‚Ñ€Ñ–Ð½Ð³Ñ–Ð² (Ð²Ñ…Ð¾Ð´Ñ–Ð²) Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€Ð° ÑÐº Ñ†Ñ–Ð»Ðµ Ñ‡Ð¸ÑÐ»Ð¾. Ð¯ÐºÑ‰Ð¾ Ð½Ðµ Ð²ÐºÐ°Ð·Ð°Ð½Ð¾ â€” Ð¿Ð¾Ð²ÐµÑ€Ð½Ð¸ 0.
- `firmware`: Ð²ÐµÑ€ÑÑ–Ñ Ð¿Ñ€Ð¾ÑˆÐ¸Ð²ÐºÐ¸ Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€Ð°. Ð¯ÐºÑ‰Ð¾ Ð½Ðµ Ð²ÐºÐ°Ð·Ð°Ð½Ð¾ â€” Ð¿Ð¾Ð²ÐµÑ€Ð½Ð¸ Ð¿Ð¾Ñ€Ð¾Ð¶Ð½Ñ–Ð¹ Ñ€ÑÐ´Ð¾Ðº "".
- `power`: Ð¿Ð¾Ñ‚ÑƒÐ¶Ð½Ñ–ÑÑ‚ÑŒ Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€Ð° Ñƒ Ð’Ñ‚. Ð¯ÐºÑ‰Ð¾ Ð½Ðµ Ð²ÐºÐ°Ð·Ð°Ð½Ð¾ â€” Ð¿Ð¾Ð²ÐµÑ€Ð½Ð¸ 0.

â€¼ï¸Ð’ÐÐ–Ð›Ð˜Ð’Ðž:
- Ð£Ð²Ð°Ð¶Ð½Ð¾ Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ñ‚ÐµÑ…Ð½Ñ–Ñ‡Ð½Ñ– Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð´Ð»Ñ Ð²Ð¸Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ Ñ‚Ð¸Ð¿Ñƒ Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€Ð° Ñ‚Ð° ÐºÑ–Ð»ÑŒÐºÐ¾ÑÑ‚Ñ– ÑÑ‚Ñ€Ñ–Ð½Ð³Ñ–Ð²
- Ð¯ÐºÑ‰Ð¾ Ñ†Ñ–Ð½Ð° Ð²Ñ–Ð´ÑÑƒÑ‚Ð½Ñ Ð°Ð±Ð¾ Ð´Ð¾Ñ€Ñ–Ð²Ð½ÑŽÑ” 0, Ð²ÑÐµ Ð¾Ð´Ð½Ð¾ Ð¿Ð¾Ð²ÐµÑ€Ð½Ð¸ Ð¾Ð±'Ñ”ÐºÑ‚, Ð°Ð»Ðµ Ð· Ñ†Ñ–Ð½Ð¾ÑŽ 0

ÐžÑÑŒ Ð´Ð°Ð½Ñ–:
{data}

â—ï¸ÐŸÐ¾Ð²ÐµÑ€Ð½Ð¸ Ð»Ð¸ÑˆÐµ Ñ‡Ð¸ÑÑ‚Ð¸Ð¹ JSON Ñƒ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ. Ð‘ÐµÐ· Ð·Ð°Ð¹Ð²Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ñƒ.
"""

    try:
        response = model.generate_content(prompt)
        response_text = response.text.strip()

        # ÐžÑ‡Ð¸Ñ‰ÐµÐ½Ð½Ñ
        if response_text.startswith("```json"):
            response_text = response_text.replace("```json", "", 1)
        if response_text.endswith("```"):
            response_text = response_text.rsplit("```", 1)[0]

        parsed = json.loads(response_text)
        print(f"âœ… ÐžÐ±Ñ€Ð¾Ð±Ð»ÐµÐ½Ð¾ Ð±Ð»Ð¾Ðº {index}: Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ {len(parsed)} Ñ–Ð½Ð²ÐµÑ€Ñ‚Ð¾Ñ€Ñ–Ð²")
        return parsed

    except Exception as e:
        print(f"âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð½Ð° Ð±Ð»Ð¾Ñ†Ñ– {index}: {e}")
        return []


async def ai_parser(all_data: str) -> List[Dict]:
    parsed_results = []
    min_request_time = 10
    
    start_time = time.time()
    result = parse_chunk(0, all_data)
    parsed_results.extend(result)

    elapsed_time = time.time() - start_time
    if elapsed_time < min_request_time:  # Ð½Ðµ Ñ‡ÐµÐºÐ°Ñ”Ð¼Ð¾ Ð¿Ñ–ÑÐ»Ñ Ð¾ÑÑ‚Ð°Ð½Ð½ÑŒÐ¾Ð³Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ
        wait_time = min_request_time - elapsed_time
        print(f"â³ Ð—Ð°Ð¿Ð¸Ñ‚ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð¾ Ð·Ð° {elapsed_time:.1f} ÑÐµÐº. ÐžÑ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð½Ñ {wait_time:.1f} ÑÐµÐºÑƒÐ½Ð´ Ð¿ÐµÑ€ÐµÐ´ Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¼ Ð·Ð°Ð¿Ð¸Ñ‚Ð¾Ð¼...")
        time.sleep(wait_time)

    return parsed_results


# ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´ Ð·Ð°Ð¿ÑƒÑÐºÑƒ:
    parsed_results = []
    base_wait_time = 10  # Ð‘Ð°Ð·Ð¾Ð²Ð¸Ð¹ Ñ‡Ð°Ñ Ð¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð½Ñ Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ…
    max_wait_time = 120  # ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ‡Ð°Ñ Ð¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð½Ñ Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ…
    consecutive_errors = 0  # Ð›Ñ–Ñ‡Ð¸Ð»ÑŒÐ½Ð¸Ðº Ð¿Ð¾ÑÐ»Ñ–Ð´Ð¾Ð²Ð½Ð¸Ñ… Ð¿Ð¾Ð¼Ð¸Ð»Ð¾Ðº
    
    for i, data in enumerate(all_data):
        start_time = time.time()
        
        # Ð¡Ð¿Ñ€Ð¾Ð±Ð° Ð· Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸ Ð¿Ñ€Ð¸ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°Ñ…
        max_retries = 3
        for retry in range(max_retries):
            try:
                result = parse_chunk(i, data)
                parsed_results.extend(result)
                consecutive_errors = 0  # Ð¡ÐºÐ¸Ð´Ð°Ñ”Ð¼Ð¾ Ð»Ñ–Ñ‡Ð¸Ð»ÑŒÐ½Ð¸Ðº Ð¿Ð¾Ð¼Ð¸Ð»Ð¾Ðº Ð¿Ñ€Ð¸ ÑƒÑÐ¿Ñ–Ñ…Ñƒ
                break
            except Exception as e:
                error_message = str(e)
                if "429" in error_message:  # ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð½Ñ ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ–
                    consecutive_errors += 1
                    
                    # Ð’Ð¸Ñ‚ÑÐ³ÑƒÑ”Ð¼Ð¾ Ñ‡Ð°Ñ Ð¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð½Ñ Ð· Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÑƒ, ÑÐºÑ‰Ð¾ Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾
                    retry_delay = 0
                    if "retry_delay" in error_message and "seconds" in error_message:
                        try:
                            # Ð¡Ð¿Ñ€Ð¾Ð±Ð° Ð²Ð¸Ñ‚ÑÐ³Ñ‚Ð¸ Ñ‡Ð¸ÑÐ»Ð¾ ÑÐµÐºÑƒÐ½Ð´ Ð· Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÑƒ
                            retry_part = error_message.split("retry_delay")[1]
                            seconds_part = retry_part.split("seconds:")[1].split("}")[0].strip()
                            retry_delay = int(seconds_part)
                        except:
                            retry_delay = 0
                    
                    # Ð Ð¾Ð·Ñ€Ð°Ñ…ÑƒÐ½Ð¾Ðº Ñ‡Ð°ÑÑƒ Ð¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð½Ñ Ð· ÐµÐºÑÐ¿Ð¾Ð½ÐµÐ½Ñ†Ñ–Ð¹Ð½Ð¸Ð¼ Ð²Ñ–Ð´ÑÑ‚ÑƒÐ¿Ð°Ð½Ð½ÑÐ¼
                    wait_time = max(
                        base_wait_time * (2 ** consecutive_errors),  # Ð•ÐºÑÐ¿Ð¾Ð½ÐµÐ½Ñ†Ñ–Ð¹Ð½Ðµ Ð²Ñ–Ð´ÑÑ‚ÑƒÐ¿Ð°Ð½Ð½Ñ
                        retry_delay + 5  # Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ð¼Ð¾ Ñ‡Ð°Ñ Ð· API + Ð·Ð°Ð¿Ð°Ñ
                    )
                    wait_time = min(wait_time, max_wait_time)  # ÐžÐ±Ð¼ÐµÐ¶ÑƒÑ”Ð¼Ð¾ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¼ Ñ‡Ð°ÑÐ¾Ð¼
                    
                    print(f"âš ï¸ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð½Ñ ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ– Ð½Ð° Ð±Ð»Ð¾Ñ†Ñ– {i}, ÑÐ¿Ñ€Ð¾Ð±Ð° {retry+1}/{max_retries}. ÐžÑ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð½Ñ {wait_time} ÑÐµÐºÑƒÐ½Ð´...")
                    time.sleep(wait_time)
                    
                    if retry == max_retries - 1:  # ÐžÑÑ‚Ð°Ð½Ð½Ñ ÑÐ¿Ñ€Ð¾Ð±Ð°
                        print(f"âŒ Ð’Ð¸Ñ‡ÐµÑ€Ð¿Ð°Ð½Ð¾ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñƒ ÐºÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ ÑÐ¿Ñ€Ð¾Ð± Ð´Ð»Ñ Ð±Ð»Ð¾ÐºÑƒ {i}")
                        break
                else:
                    # Ð†Ð½ÑˆÐ° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°, Ð½Ðµ Ð¿Ð¾Ð²'ÑÐ·Ð°Ð½Ð° Ð· Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð½ÑÐ¼ ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ–
                    print(f"âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð½Ð° Ð±Ð»Ð¾Ñ†Ñ– {i}: {e}")
                    break
        
        # Ð—Ð°Ð²Ð¶Ð´Ð¸ Ñ‡ÐµÐºÐ°Ñ”Ð¼Ð¾ Ð¼Ñ–Ð¶ Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ð¼Ð¸, Ð½Ð°Ð²Ñ–Ñ‚ÑŒ Ð¿Ñ–ÑÐ»Ñ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ¸
        elapsed_time = time.time() - start_time
        
        # ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¸Ð¹ Ñ‡Ð°Ñ Ð¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð½Ñ Ð² Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ÑÑ‚Ñ– Ð²Ñ–Ð´ ÐºÑ–Ð»ÑŒÐºÐ¾ÑÑ‚Ñ– Ð¿Ð¾ÑÐ»Ñ–Ð´Ð¾Ð²Ð½Ð¸Ñ… Ð¿Ð¾Ð¼Ð¸Ð»Ð¾Ðº
        adaptive_wait_time = base_wait_time * (1 + (consecutive_errors * 0.5))
        
        if elapsed_time < adaptive_wait_time and i < len(all_data) - 1:
            wait_time = adaptive_wait_time - elapsed_time
            print(f"â³ Ð—Ð°Ð¿Ð¸Ñ‚ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð¾ Ð·Ð° {elapsed_time:.1f} ÑÐµÐº. ÐžÑ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð½Ñ {wait_time:.1f} ÑÐµÐºÑƒÐ½Ð´ Ð¿ÐµÑ€ÐµÐ´ Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¼ Ð·Ð°Ð¿Ð¸Ñ‚Ð¾Ð¼...")
            time.sleep(wait_time)

    return parsed_results
